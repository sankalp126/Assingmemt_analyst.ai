# -*- coding: utf-8 -*-
"""analyst.ai

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UWRb2jH5ofGY6HU-Q8_-zyeK5tTOaimW
"""

!pip install requests
!pip install html5lib
!pip install bs4

import pandas as pd
from bs4 import BeautifulSoup

import requests

url="https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1"

r=requests.get(url,headers={"User-Agent": "YZ"})

soup=BeautifulSoup(r.content,'html.parser')

print(soup.prettify())

div_data=soup.find_all("div",attrs={"class":"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right"})

len(div_data)

print((div_data)[0].prettify())

# <span class="a-size-medium a-color-base a-text-normal">
#        URBAN TRIBE Havana 15.6" inch Laptop Backpack for Men and Women | 27L Office/Work/Casual Bag | Water Repellent | Black
#       </span>
#     <span class="a-offscreen">â‚¹998 </span>
#     <span class="a-icon-alt">3.9 out of 5 stars</span>
#       <span class="a-size-base s-underline-text">684</span>
#       <a class="a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal" target="_blank" href="/sspa/click?ie=UTF8&amp;spc=MToyNzk5ODY1ODc2MDkxNTUzOjE2NzU0MjQzNzU6c3BfYXRmOjIwMTA0MTQwMjYzNjk4OjowOjo&amp;url=%2FUrban-Tribe-Laptop-Backpack-Havana%2Fdp%2FB01LXNNFDF%2Fref%3Dsr_1_1_sspa%3Fcrid%3D2M096C61O4MLT%26keywords%3Dbags%26qid%3D1675424375%26sprefix%3Dba%252Caps%252C283%26sr%3D8-1-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1"><span class="a-size-medium a-color-base a-text-normal">URBAN TRIBE Havana 15.6" inch Laptop Backpack for Men and Women | 27L Office/Work/Casual Bag | Water Repellent | Black</span> </a>

from bs4 import BeautifulSoup
import requests
website='https://www.amazon.in/s?k=bags&page=3&crid=2M096C61O4MLT&qid=1675442339&sprefix=ba%2Caps%2C283&ref=sr_pg_3'

r=requests.get(website,headers={"User-Agent": "YZ"})
soup=BeautifulSoup(r.content,'html.parser')

soup

liiiii=soup.find("a",attrs={"class":"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator"})
print(liiiii.get('href'))
for i in soup.find('a', href = True):
  if("www.geeksforgeeks.org" in i['href']):
    nextpage = requests.get(i['href'])    
    nextsoup = BeautifulSoup(nextpage.content, 'html.parser')
    print("next url title : ",nextsoup.find('title').string)

product_url=[]
  product_name=[]
  price=[]
  rating=[]
  number_of_reviews=[]

def ansde(link):
  print(link)
  r=requests.get(link,headers={"User-Agent": "YZ"})
  soup=BeautifulSoup(r.content,'html.parser')
  div_data=soup.find_all("div",attrs={"class":"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right"})
  link=soup.find("a",attrs={"class":"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator"})
  if(link==None):
    return
  l="https://www.amazon.in"+link.get('href')
  
  for i in div_data:
    try:
      product_url.append("https://www.amazon.in/"+i.find('a',attrs={'class':"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal"}).get('href'))
    except:
      product_url.append(None)
    try:
      product_name.append(i.find('span',attrs={'class':"a-size-medium a-color-base a-text-normal"}).get_text())
    except:
      product_name.append(None)
    try:
      price.append(i.find('span',attrs={'class':"a-offscreen"}).get_text())
    except:
      price.append(None)
    try:
      rating.append(i.find('span',attrs={'class':"a-size-base"}).get_text())
    except:
      rating.append(None)
    try:
      number_of_reviews.append(i.find('span',attrs={'class':"a-size-base s-underline-text"}).get_text())
    except:
      number_of_reviews.append(None)

  return ansde(l)

ansde("https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1675443218&sprefix=ba%2Caps%2C283&ref=sr_pg_1")

mp={}
import pandas as pd
mp['product_url']=product_url
mp['product_name']=product_name
mp['price']=price
mp['rating']=rating
mp['number_of_reviews']=number_of_reviews



df

for i in range(len(df['price'])):
  df['price'][i]=df['price'][i][1:]

df

r=requests.get(product_url[0],headers={"User-Agent": "XYZ"})
soup=BeautifulSoup(r.content,'html.parser')

product_description=[]
ASIN=[]
manufacturer=[]
# def part2():
for link in product_url:
  try:
    r=requests.get(link,headers={"User-Agent": "XYZ"})
    soup=BeautifulSoup(r.content,'html.parser')
    description=soup.find('div',attrs={'id':"featurebullets_feature_div"})
    dd=soup.find('div',attrs={'class':"a-section table-padding"})
    manu=soup.find('div',attrs={'class':"a-expander-content a-expander-section-content a-section-expander-inner"})
    description=soup.find('div',attrs={'id':"featurebullets_feature_div"})
    # print(manu)
    manufac=manu.find_all('td',attrs={'class':"a-size-base prodDetAttrValue"})
    m_data=manufac[8].text
    # a-section table-padding
    asin=dd.find('td',attrs={'class':"a-size-base prodDetAttrValue"}).text
    x=description.find('ul')
    desc=""
    for li in x.find_all("li"):
      desc=desc+","+li.text
    product_description.append(desc)
    ASIN.append(asin)
    manufacturer.append(m_data)
  except:
    product_description.append(None)
    ASIN.append(None)
    manufacturer.append(None)

      # print(li.text, end=" ")

m=[]
for i in manufacturer:
  try:
    m.append("".join(i.split())[2:])
  except:
    m.append(None)

m

mp["ASIN"]=ASIN
mp["product_description"]=product_description
mp["manufacturer"]=m



manufacturer

df=pd.DataFrame(mp)

df.to_csv("results.csv")

df

